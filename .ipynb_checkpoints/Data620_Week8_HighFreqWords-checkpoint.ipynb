{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Week 8 - – High Frequency Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Betsy Rosalen and Mikhail Groysman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please answer the following questions in an IPython Notebook, posted to GitHub.\n",
    "1. Choose a corpus of interest.\n",
    "2. How many total unique words are in the corpus? (Please feel free to define unique words in any interesting,\n",
    "defensible way).\n",
    "3. Taking the most common words, how many unique words represent half of the total words in the corpus?\n",
    "4. Identify the 200 highest frequency words in this corpus.\n",
    "5. Create a graph that shows the relative frequency of these 200 words.\n",
    "6. Does the observed relative frequency of these words follow Zipf’s law? Explain.\n",
    "7. In what ways do you think the frequency of the words in this corpus differ from “all words in all corpora.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Choosing a corpus of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We went an easy way, selecting one of the corpus from freely available library Gutenburg. Our corpus is Persuasion writtne by Jane Austen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /Users/betsyrosalen/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "austen = nltk.Text(nltk.corpus.gutenberg.words('austen-persuasion.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Total Unique Words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### How many total unique words are in the corpus? (Please feel free to define unique words in any interesting, defensible way)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98171"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AW=len(austen)\n",
    "AW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique words:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at a portion distribution of our words, we can see that it includes punctuation and numbers as well as words.  We also know that python will see capital letters as distinct from lowercase letters, so we need to convert all words to lowercase and remove punctuation and numbers to get only the unique words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excluding punctuation, numbers and removing capitalization. This code comes from the textbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5739"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AWwoNP=[word.lower() for word in austen if word.isalpha()]\n",
    "len(set(AWwoNP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer: 5,739__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. How many unique words represent half of all words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Taking the most common words, how many unique words represent half of the total words in the corpus?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the list of just the unique words excluding numbers and punctuation we create a frequency distribution of the words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 3329),\n",
       " ('to', 2808),\n",
       " ('and', 2801),\n",
       " ('of', 2570),\n",
       " ('a', 1595),\n",
       " ('in', 1389),\n",
       " ('was', 1337),\n",
       " ('her', 1204),\n",
       " ('had', 1186),\n",
       " ('she', 1146)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist = nltk.FreqDist(AWwoNP).most_common()\n",
    "fdist[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using that frequency distribution we can write a function to add the frequency counts of the most frequent words one by one (in order from most frequent to least) until their total count reaches half the total word count and keep a running tally of how many word frequencies were added until we reached half the total word count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n"
     ]
    }
   ],
   "source": [
    "tw=len(AWwoNP) # total number of words in the corpus\n",
    "tcount=0\n",
    "wcount=0\n",
    "for word, count in fdist:\n",
    "    tcount=tcount+count\n",
    "    wcount=wcount+1\n",
    "    if tcount>(tw/2):\n",
    "        print(wcount)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__58 unique words represent half of the total words in the corpus.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 200 most frequent words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Identify the 200 highest frequency words in this corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "      <td>3329</td>\n",
       "      <td>anne</td>\n",
       "      <td>497</td>\n",
       "      <td>this</td>\n",
       "      <td>250</td>\n",
       "      <td>might</td>\n",
       "      <td>166</td>\n",
       "      <td>how</td>\n",
       "      <td>125</td>\n",
       "      <td>out</td>\n",
       "      <td>95</td>\n",
       "      <td>family</td>\n",
       "      <td>80</td>\n",
       "      <td>back</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>to</td>\n",
       "      <td>2808</td>\n",
       "      <td>been</td>\n",
       "      <td>496</td>\n",
       "      <td>an</td>\n",
       "      <td>245</td>\n",
       "      <td>own</td>\n",
       "      <td>163</td>\n",
       "      <td>miss</td>\n",
       "      <td>125</td>\n",
       "      <td>house</td>\n",
       "      <td>94</td>\n",
       "      <td>felt</td>\n",
       "      <td>80</td>\n",
       "      <td>off</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>and</td>\n",
       "      <td>2801</td>\n",
       "      <td>s</td>\n",
       "      <td>485</td>\n",
       "      <td>than</td>\n",
       "      <td>243</td>\n",
       "      <td>well</td>\n",
       "      <td>163</td>\n",
       "      <td>your</td>\n",
       "      <td>124</td>\n",
       "      <td>say</td>\n",
       "      <td>93</td>\n",
       "      <td>give</td>\n",
       "      <td>79</td>\n",
       "      <td>admiral</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>of</td>\n",
       "      <td>2570</td>\n",
       "      <td>him</td>\n",
       "      <td>467</td>\n",
       "      <td>one</td>\n",
       "      <td>238</td>\n",
       "      <td>did</td>\n",
       "      <td>162</td>\n",
       "      <td>most</td>\n",
       "      <td>123</td>\n",
       "      <td>seemed</td>\n",
       "      <td>93</td>\n",
       "      <td>away</td>\n",
       "      <td>78</td>\n",
       "      <td>came</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>a</td>\n",
       "      <td>1595</td>\n",
       "      <td>could</td>\n",
       "      <td>451</td>\n",
       "      <td>must</td>\n",
       "      <td>228</td>\n",
       "      <td>herself</td>\n",
       "      <td>159</td>\n",
       "      <td>see</td>\n",
       "      <td>123</td>\n",
       "      <td>having</td>\n",
       "      <td>92</td>\n",
       "      <td>way</td>\n",
       "      <td>78</td>\n",
       "      <td>smith</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>in</td>\n",
       "      <td>1389</td>\n",
       "      <td>very</td>\n",
       "      <td>434</td>\n",
       "      <td>when</td>\n",
       "      <td>228</td>\n",
       "      <td>now</td>\n",
       "      <td>158</td>\n",
       "      <td>soon</td>\n",
       "      <td>122</td>\n",
       "      <td>up</td>\n",
       "      <td>91</td>\n",
       "      <td>ever</td>\n",
       "      <td>78</td>\n",
       "      <td>woman</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>was</td>\n",
       "      <td>1337</td>\n",
       "      <td>they</td>\n",
       "      <td>433</td>\n",
       "      <td>my</td>\n",
       "      <td>223</td>\n",
       "      <td>never</td>\n",
       "      <td>155</td>\n",
       "      <td>though</td>\n",
       "      <td>117</td>\n",
       "      <td>thought</td>\n",
       "      <td>90</td>\n",
       "      <td>uppercross</td>\n",
       "      <td>77</td>\n",
       "      <td>lyme</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>her</td>\n",
       "      <td>1204</td>\n",
       "      <td>were</td>\n",
       "      <td>426</td>\n",
       "      <td>being</td>\n",
       "      <td>220</td>\n",
       "      <td>we</td>\n",
       "      <td>155</td>\n",
       "      <td>father</td>\n",
       "      <td>117</td>\n",
       "      <td>elizabeth</td>\n",
       "      <td>89</td>\n",
       "      <td>day</td>\n",
       "      <td>77</td>\n",
       "      <td>just</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>had</td>\n",
       "      <td>1186</td>\n",
       "      <td>by</td>\n",
       "      <td>418</td>\n",
       "      <td>only</td>\n",
       "      <td>219</td>\n",
       "      <td>time</td>\n",
       "      <td>152</td>\n",
       "      <td>before</td>\n",
       "      <td>116</td>\n",
       "      <td>however</td>\n",
       "      <td>89</td>\n",
       "      <td>come</td>\n",
       "      <td>75</td>\n",
       "      <td>another</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>she</td>\n",
       "      <td>1146</td>\n",
       "      <td>which</td>\n",
       "      <td>416</td>\n",
       "      <td>wentworth</td>\n",
       "      <td>218</td>\n",
       "      <td>sir</td>\n",
       "      <td>149</td>\n",
       "      <td>two</td>\n",
       "      <td>114</td>\n",
       "      <td>last</td>\n",
       "      <td>88</td>\n",
       "      <td>feelings</td>\n",
       "      <td>75</td>\n",
       "      <td>clay</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>i</td>\n",
       "      <td>1124</td>\n",
       "      <td>is</td>\n",
       "      <td>398</td>\n",
       "      <td>lady</td>\n",
       "      <td>216</td>\n",
       "      <td>think</td>\n",
       "      <td>149</td>\n",
       "      <td>first</td>\n",
       "      <td>113</td>\n",
       "      <td>make</td>\n",
       "      <td>88</td>\n",
       "      <td>harville</td>\n",
       "      <td>75</td>\n",
       "      <td>present</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>it</td>\n",
       "      <td>1038</td>\n",
       "      <td>on</td>\n",
       "      <td>396</td>\n",
       "      <td>such</td>\n",
       "      <td>211</td>\n",
       "      <td>russell</td>\n",
       "      <td>148</td>\n",
       "      <td>quite</td>\n",
       "      <td>112</td>\n",
       "      <td>go</td>\n",
       "      <td>88</td>\n",
       "      <td>still</td>\n",
       "      <td>74</td>\n",
       "      <td>our</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>he</td>\n",
       "      <td>961</td>\n",
       "      <td>so</td>\n",
       "      <td>359</td>\n",
       "      <td>do</td>\n",
       "      <td>210</td>\n",
       "      <td>are</td>\n",
       "      <td>146</td>\n",
       "      <td>louisa</td>\n",
       "      <td>111</td>\n",
       "      <td>place</td>\n",
       "      <td>87</td>\n",
       "      <td>done</td>\n",
       "      <td>74</td>\n",
       "      <td>going</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>be</td>\n",
       "      <td>950</td>\n",
       "      <td>no</td>\n",
       "      <td>356</td>\n",
       "      <td>much</td>\n",
       "      <td>205</td>\n",
       "      <td>other</td>\n",
       "      <td>143</td>\n",
       "      <td>always</td>\n",
       "      <td>110</td>\n",
       "      <td>may</td>\n",
       "      <td>87</td>\n",
       "      <td>henrietta</td>\n",
       "      <td>74</td>\n",
       "      <td>heard</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>not</td>\n",
       "      <td>934</td>\n",
       "      <td>would</td>\n",
       "      <td>355</td>\n",
       "      <td>if</td>\n",
       "      <td>202</td>\n",
       "      <td>walter</td>\n",
       "      <td>141</td>\n",
       "      <td>without</td>\n",
       "      <td>108</td>\n",
       "      <td>better</td>\n",
       "      <td>87</td>\n",
       "      <td>kellynch</td>\n",
       "      <td>73</td>\n",
       "      <td>mind</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>that</td>\n",
       "      <td>882</td>\n",
       "      <td>captain</td>\n",
       "      <td>303</td>\n",
       "      <td>any</td>\n",
       "      <td>199</td>\n",
       "      <td>nothing</td>\n",
       "      <td>139</td>\n",
       "      <td>can</td>\n",
       "      <td>107</td>\n",
       "      <td>many</td>\n",
       "      <td>85</td>\n",
       "      <td>sure</td>\n",
       "      <td>73</td>\n",
       "      <td>happy</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>as</td>\n",
       "      <td>809</td>\n",
       "      <td>from</td>\n",
       "      <td>295</td>\n",
       "      <td>what</td>\n",
       "      <td>197</td>\n",
       "      <td>mary</td>\n",
       "      <td>138</td>\n",
       "      <td>every</td>\n",
       "      <td>102</td>\n",
       "      <td>over</td>\n",
       "      <td>84</td>\n",
       "      <td>its</td>\n",
       "      <td>72</td>\n",
       "      <td>something</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>for</td>\n",
       "      <td>707</td>\n",
       "      <td>their</td>\n",
       "      <td>293</td>\n",
       "      <td>who</td>\n",
       "      <td>190</td>\n",
       "      <td>am</td>\n",
       "      <td>137</td>\n",
       "      <td>bath</td>\n",
       "      <td>101</td>\n",
       "      <td>same</td>\n",
       "      <td>84</td>\n",
       "      <td>those</td>\n",
       "      <td>72</td>\n",
       "      <td>indeed</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>but</td>\n",
       "      <td>664</td>\n",
       "      <td>mrs</td>\n",
       "      <td>291</td>\n",
       "      <td>should</td>\n",
       "      <td>188</td>\n",
       "      <td>some</td>\n",
       "      <td>136</td>\n",
       "      <td>has</td>\n",
       "      <td>100</td>\n",
       "      <td>young</td>\n",
       "      <td>84</td>\n",
       "      <td>upon</td>\n",
       "      <td>72</td>\n",
       "      <td>here</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>his</td>\n",
       "      <td>659</td>\n",
       "      <td>elliot</td>\n",
       "      <td>289</td>\n",
       "      <td>me</td>\n",
       "      <td>188</td>\n",
       "      <td>man</td>\n",
       "      <td>134</td>\n",
       "      <td>into</td>\n",
       "      <td>98</td>\n",
       "      <td>found</td>\n",
       "      <td>83</td>\n",
       "      <td>enough</td>\n",
       "      <td>71</td>\n",
       "      <td>few</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>with</td>\n",
       "      <td>654</td>\n",
       "      <td>there</td>\n",
       "      <td>286</td>\n",
       "      <td>good</td>\n",
       "      <td>187</td>\n",
       "      <td>again</td>\n",
       "      <td>132</td>\n",
       "      <td>about</td>\n",
       "      <td>97</td>\n",
       "      <td>friend</td>\n",
       "      <td>83</td>\n",
       "      <td>even</td>\n",
       "      <td>71</td>\n",
       "      <td>party</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>you</td>\n",
       "      <td>628</td>\n",
       "      <td>or</td>\n",
       "      <td>274</td>\n",
       "      <td>little</td>\n",
       "      <td>176</td>\n",
       "      <td>musgrove</td>\n",
       "      <td>130</td>\n",
       "      <td>after</td>\n",
       "      <td>96</td>\n",
       "      <td>home</td>\n",
       "      <td>83</td>\n",
       "      <td>moment</td>\n",
       "      <td>71</td>\n",
       "      <td>acquaintance</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>have</td>\n",
       "      <td>589</td>\n",
       "      <td>more</td>\n",
       "      <td>273</td>\n",
       "      <td>said</td>\n",
       "      <td>173</td>\n",
       "      <td>great</td>\n",
       "      <td>130</td>\n",
       "      <td>made</td>\n",
       "      <td>96</td>\n",
       "      <td>sister</td>\n",
       "      <td>82</td>\n",
       "      <td>then</td>\n",
       "      <td>70</td>\n",
       "      <td>down</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>at</td>\n",
       "      <td>533</td>\n",
       "      <td>them</td>\n",
       "      <td>270</td>\n",
       "      <td>will</td>\n",
       "      <td>167</td>\n",
       "      <td>too</td>\n",
       "      <td>128</td>\n",
       "      <td>himself</td>\n",
       "      <td>95</td>\n",
       "      <td>room</td>\n",
       "      <td>82</td>\n",
       "      <td>benwick</td>\n",
       "      <td>70</td>\n",
       "      <td>knew</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>all</td>\n",
       "      <td>530</td>\n",
       "      <td>mr</td>\n",
       "      <td>256</td>\n",
       "      <td>charles</td>\n",
       "      <td>166</td>\n",
       "      <td>know</td>\n",
       "      <td>127</td>\n",
       "      <td>long</td>\n",
       "      <td>95</td>\n",
       "      <td>like</td>\n",
       "      <td>81</td>\n",
       "      <td>while</td>\n",
       "      <td>69</td>\n",
       "      <td>almost</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  count     word  count       word  count      word  count     word  \\\n",
       "0    the   3329     anne    497       this    250     might    166      how   \n",
       "1     to   2808     been    496         an    245       own    163     miss   \n",
       "2    and   2801        s    485       than    243      well    163     your   \n",
       "3     of   2570      him    467        one    238       did    162     most   \n",
       "4      a   1595    could    451       must    228   herself    159      see   \n",
       "5     in   1389     very    434       when    228       now    158     soon   \n",
       "6    was   1337     they    433         my    223     never    155   though   \n",
       "7    her   1204     were    426      being    220        we    155   father   \n",
       "8    had   1186       by    418       only    219      time    152   before   \n",
       "9    she   1146    which    416  wentworth    218       sir    149      two   \n",
       "10     i   1124       is    398       lady    216     think    149    first   \n",
       "11    it   1038       on    396       such    211   russell    148    quite   \n",
       "12    he    961       so    359         do    210       are    146   louisa   \n",
       "13    be    950       no    356       much    205     other    143   always   \n",
       "14   not    934    would    355         if    202    walter    141  without   \n",
       "15  that    882  captain    303        any    199   nothing    139      can   \n",
       "16    as    809     from    295       what    197      mary    138    every   \n",
       "17   for    707    their    293        who    190        am    137     bath   \n",
       "18   but    664      mrs    291     should    188      some    136      has   \n",
       "19   his    659   elliot    289         me    188       man    134     into   \n",
       "20  with    654    there    286       good    187     again    132    about   \n",
       "21   you    628       or    274     little    176  musgrove    130    after   \n",
       "22  have    589     more    273       said    173     great    130     made   \n",
       "23    at    533     them    270       will    167       too    128  himself   \n",
       "24   all    530       mr    256    charles    166      know    127     long   \n",
       "\n",
       "    count       word  count        word  count          word  count  \n",
       "0     125        out     95      family     80          back     69  \n",
       "1     125      house     94        felt     80           off     69  \n",
       "2     124        say     93        give     79       admiral     69  \n",
       "3     123     seemed     93        away     78          came     68  \n",
       "4     123     having     92         way     78         smith     68  \n",
       "5     122         up     91        ever     78         woman     67  \n",
       "6     117    thought     90  uppercross     77          lyme     67  \n",
       "7     117  elizabeth     89         day     77          just     66  \n",
       "8     116    however     89        come     75       another     66  \n",
       "9     114       last     88    feelings     75          clay     66  \n",
       "10    113       make     88    harville     75       present     65  \n",
       "11    112         go     88       still     74           our     65  \n",
       "12    111      place     87        done     74         going     65  \n",
       "13    110        may     87   henrietta     74         heard     65  \n",
       "14    108     better     87    kellynch     73          mind     64  \n",
       "15    107       many     85        sure     73         happy     64  \n",
       "16    102       over     84         its     72     something     64  \n",
       "17    101       same     84       those     72        indeed     63  \n",
       "18    100      young     84        upon     72          here     63  \n",
       "19     98      found     83      enough     71           few     62  \n",
       "20     97     friend     83        even     71         party     62  \n",
       "21     96       home     83      moment     71  acquaintance     61  \n",
       "22     96     sister     82        then     70          down     61  \n",
       "23     95       room     82     benwick     70          knew     61  \n",
       "24     95       like     81       while     69        almost     60  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''w1 = pd.DataFrame(fdist[:25])\n",
    "w2 = pd.DataFrame(fdist[25:50])\n",
    "w2 = pd.DataFrame(fdist[50:75])\n",
    "w2 = pd.DataFrame(fdist[75:100])\n",
    "w3 = pd.DataFrame(fdist[100:125])\n",
    "w4 = pd.DataFrame(fdist[125:150])\n",
    "w4 = pd.DataFrame(fdist[150:175])\n",
    "w4 = pd.DataFrame(fdist[175:200])'''\n",
    "flist = []\n",
    "for i in range(0, 200, 25):\n",
    "    df = pd.DataFrame(fdist[i:(i+25)])\n",
    "    df.columns=['word', 'count']\n",
    "    flist.append(df)\n",
    "\n",
    "pd.concat(flist, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Relative frequency of these 200 words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Create a graph that shows the relative frequency of these 200 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "wcount=0\n",
    "for word, count in fdist:       \n",
    "    wcount=wcount+1\n",
    "    my_dict[word]=count/tw\n",
    "    if wcount>199:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(17,5))\n",
    "plt.xticks(rotation=90)\n",
    "plt.rc('xtick',labelsize=4)\n",
    "plt.bar(my_dict.keys(), my_dict.values(), width=.4, color='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Zipf's law"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Does the observed relative frequency of these words follow Zipf’s law? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Wikipedia:\n",
    "\n",
    "Zipf's law was originally formulated in terms of quantitative linguistics , stating that given some corpus of natural language utterances, the frequency of any word is inversely proportional to its rank in the frequency table. Thus the most frequent word will occur approximately twice as often as the second most frequent word, three times as often as the third most frequent word, etc.: the rank-frequency distribution is an inverse relation. For example, in the Brown Corpus of American English text, the word the is the most frequently occurring word, and by itself accounts for nearly 7% of all word occurrences (69,971 out of slightly over 1 million). True to Zipf's Law, the second-place word of accounts for slightly over 3.5% of words (36,411 occurrences), followed by and (28,852). Only 135 vocabulary items are needed to account for half the Brown Corpus.[1]\n",
    "\n",
    "[1](https://en.wikipedia.org/wiki/Zipf%27s_law)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see hpw much our value are off from Zipf's distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcount=0\n",
    "for word, count in fdist: \n",
    "    if wcount==0:\n",
    "        fval=count\n",
    "    else:\n",
    "        #print(fval,word,count,fval/(wcount+1))\n",
    "        print(wcount+1,fval/count)\n",
    "    wcount=wcount+1\n",
    "    if wcount>199:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does not follow original Zipf's law exactly. If it did then we would have 2 2, 3 3, 4 4, etc. But our distribution has Zipf's quality. It decreases exponentially, not linearly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let try to calculate S of our Zipf function using code from stackoverflow.[2]\n",
    "\n",
    "[2](https://stackoverflow.com/questions/43671188/zipf-distribution-how-do-i-measure-zipf-distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from operator import itemgetter\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import special\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "frequency = {key:value for key,value in my_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = list(frequency.keys())\n",
    "s1 = np.array(s)\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=2\n",
    "plt.rc('xtick',labelsize=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count, bins, ignored = plt.hist(s1[s1<50], 50, cumulative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1., 25.)\n",
    "y = x**(-a) / special.zetac(a)\n",
    "x\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y/max(y), linewidth=2, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Compare with 'all words in all corpora' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In what ways do you think the frequency of the words in this corpus differ from “all words in all corpora.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
